\subsection{The Moment Generating Function}\label{s:MGF}
Having defined the techniques required to compute fractional derivatives, we now turn to their application to the Moment Generating Function (MGF). Before proceeding, we will briefly review some key concepts related to statistical moments.
\subsubsection{Moments}
\begin{definition}
    Let \(X\) be a random variable.
    The \(\alpha\)-th moment of a \(X\) is defined as:
   \[
\mathbb{E}[X^\alpha] = 
\begin{cases} 
\int_{-\infty}^{\infty} (x - c)^\alpha f_X(x) \, dx & \text{if } X \text{ is continuous,} \\ 
\sum_{i} (x_i - c_ i)^\alpha f_X(x_i) & \text{if } X \text{ is discrete.} 
\end{cases}
\] with, in the context of this paper \(\alpha \in \mathbb{R}\). Here \(f_X(x)\) is the probability density function if \(X\) is a continuous random variable, and the probability mass function if \(X\) is a discrete random variable \cite{feller1957}.
\end{definition}

If \(c = \mu_x\), the first moment of \(f(x)\), then our higher moments are called central moments. In the context of this research, we will focus on the case \(c = 0\), corresponding to raw moments of a random variable \(X\). This choice has been made as the Moment Generating Function, which we will soon define, only computes raw moments of higher order. A moment of order \(\alpha\) is said to exist, if \(\mathbb{E}[X^\alpha] < \infty\).

\subsubsection{The Moment Generating Function}
We now formally introduce the Moment Generating Function, one of the most significant subjects of this thesis.
\begin{definition}
    The Moment Generating Function (MGF) of a variable \(X\), is defined as
    \[M_X(t) = \mathbb{E}[e^{tX}]\] provided that \(\mathbb{E}[e^{tX}] < \infty\), for all  \( t \in (- h, h)\), which contains 0, for some \(h > 0\) \cite{mackey1980}.
\end{definition}

\begin{remark}
    Deriving the expression \(M_X(t) = \mathbb{E}[e^{tX}]\) is typically straightforward. Generally, it simply requires a handful of steps of analytic evaluation. This procedure is not that interesting nor relevant to this research. Thus, when making use of  expressions of the Moment Generating Function, we will simply refer to the distribution table in Appendix \ref{s:app_common_distributions}.
\end{remark}

 
We will state the theorem which makes the MGF so useful. This theorem allows us to compute moments of higher order by taking derivatives of the given order instead of integrals.
\begin{theorem}\label{t:mgf}
    If \(M_X(t)\) exists on some interval \((-h, h)\), as defined before, we have that:
    \[ \mathbb{E}[X^n] = M_X^{(n)}(0), \text{ for } n \in \mathbb{N}\]  \cite{casella2002}
\end{theorem} 




We introduce the following properties for the Moment Generating Function \(M_X(t)\):
\begin{proposition}\label{p: moments}
    For \(X, Y\) random variables, we have that:
    \begin{enumerate}[(i)]
        \item \(M_X^{(0)}(t) = \mathbb{E}[e^{0X}] = 1\). This property can be used to confirm that a given function is a valid probability density function (i.e., integrates to one).
        \item Location scale-transform. Assuming \(M_X(t)\) exists, for constant \(\mu, \sigma\), we have that: 
        \[M_{\mu + \sigma X}(t) = e^{\mu t} \cdot M_X(\sigma t)\]
        \item If \(X \perp Y\), then \(M_{X+Y}(t) = M_X(t)\cdot M_Y(t)\).
    \end{enumerate}
\end{proposition}
\cite{lin2022}

The proofs of the latter can be found in Appendix \ref{s:app_B}.

There are several additional topics closely related to the MGF, including Fourier transforms, Laplace transforms, Wick rotations, and characteristic functions. While these subjects are relevant to the theoretical foundation of the MGF , they fall outside the scope of this paper and will therefore not be discussed. Readers interested in exploring these concepts further may find \cite{kolmogorov1999} to be a valuable resource.

\subsubsection{Computing negative moments using the Moment Generating Function}
In specific cases, as were mentioned in section \ref{s:intro}, moments of negative order can be of interest to characterize the data. Such an example was the moment of order \(-\frac{1}{2}\), which in some contexts may be used to obtain the Sharpe Ratio. Thus, it is useful to understand how to compute moments of such orders. We will consider the continuous case:

\[\mathbb{E}[X^{-n}] = \int_{-\infty}^{\infty} x^{-n} f_X(x) dx = \int_{-\infty}^{\infty} \left(\frac{1}{x}\right)^n f_X(x) dx.\] We immediately observe a rather obvious problem. This integral is undefined at \(x = 0\) and diverges in a neighbourhood around zero. \cite{khuri2002} have stated the following corollary for the existence of a moment with negative first order:
\begin{corollary}
    If \(f_X(x)\) is a continuous pdf defined on \((-\infty, \infty)\), and if \[\lim_{x \to 0} \frac{f_X(x)}{|x|^\alpha} < \infty\] for \(\alpha > 0\), then \[\mathbb{E}[X^{-1}] \text{ exists}.\]
\end{corollary}

Most common distribution functions do not adhere to this corollary, however, the Gamma function does (see \ref{p:negative}).

If such a moment of negative order exists, we should be able to obtain it using the Moment Generating Function. In the 20-th century, \cite{cressie1981} have published the following remarkable theorem:

\begin{theorem}\label{t: negative}
    Assuming the negative \(n\)-th raw moment exists, the negative \(n\)-th raw moment can be computed as follows: 
    \[\mathbb{E}[X^{-n}] = \frac{1}{\Gamma(n)} \int_{0}^{\infty} t^{n- 1} M_X(-t) dt\] where \(n\) is a positive integer.
\end{theorem}
The proof of this Theorem can be found in Appendix \ref{s:app_B}.

Since this is an extension on the regular functions of the MGF, this technique is of interest of this paper. Thus, it will be shortly be discussed. We compute the first inverse moment of the Gamma distribution, by making use of the latter theorem for Moment Generating Functions.

\begin{example}
    Let \[f_X(x) \sim \Gamma(\alpha, \lambda) = 
    \frac{x^{\alpha -1} e^{-\lambda x} \lambda^\alpha} {\Gamma(\alpha)}, M_X(t) = \left(\frac{\lambda}{\lambda - t}\right)^\alpha\]
    \[\mathbb{E}[X^{-1}] = \frac{1}{\Gamma(1)} \int_{0}^{\infty} t^{( 1 - 1)} \left(\frac{\lambda}{\lambda - (-t)}\right)^\alpha dt =  \int_{0}^{\infty} \left(\frac{\lambda}{\lambda + t}\right)^\alpha dt\]
    \[ = \lambda^\alpha \int_{0}^{\infty} (\lambda + t)^{-\alpha} dt, \text{ Let } u = \lambda + t, \frac{du}{dt} = 1, dt = du:\]
    \[ \lambda^\alpha \int_{0}^{\infty} u^{-\alpha} du
    =  \lambda^\alpha \frac{u^{ 1-\alpha}}{1 -\alpha}\Big|_{0}^{\infty} = \lambda^\alpha \frac{(\lambda + t)^{1 -\alpha}}{1 -\alpha}\Big|_{0}^{\infty}\]
    \[= \lambda^\alpha\left( 0 - \frac{\lambda^{ 1 - \alpha}}{1 -\alpha}\right) = \frac{-\lambda}{ 1 - \alpha} = \frac{\lambda}{\alpha - 1}.\] Which corresponds with our result from example \ref{p:negative}.
\end{example}

\subsubsection{Extending the MGF to fractional order}
Now that we have introduced the definitions of the MGF and discussed a number of relevant properties, we will combine these with the techniques developed in section \ref{s:calculus}. Therefore, we can at last obtain moments of fractional order using the MGF.


To avoid confusion regarding what fractional derivative is being used in combination with the MGF, we will from now on, work with the following notation:
\begin{definition}\label{d: MGF}
    We define the MGF of order \(\alpha \in \mathbb{R}\) by \(\leftindex_{RL}{M}_X^{(\alpha)}, \leftindex_{CF}{M}_X^{(\alpha)}, \leftindex_{GL}{M}_X^{(\alpha)}\) for the MGF in combination with the Riemann-Liouville, Caputo-Fabrizio and Gr√ºnwald-Letnikov fractional derivative respectively.
\end{definition}
\begin{remark}
    The three properties mentioned in proposition \ref{p: moments} still hold for the MGF of fractional order. This is the case as the first property makes makes use of the derivative of order 0. Which has been defined to just be the original function itself as stated in the second property of proposition\ref{p: calculus}. The other two properties do not involve any derivatives of any order. Thus, they are generally applicable to the MGF, regardless of its order or kind of derivative.
\end{remark}

Before stating any results about the accuracy of these new MGF expressions, we first consider a numerical example to illustrate the interaction between fractional derivatives and the MGF. 

\begin{example}
    \begin{enumerate}[(i)]
        \item We let \(f_X(x_i) \sim Bernoulli(p)\), with \(\mathbb{P}(X = 1) = p\) and with associated MGF expression: \(M_X(t) = (1 - p) + p \cdot\exp(t)\), now we consider \[\leftindex_{CF}{M}_X^{(\frac{1}{2})} = \frac{1}{1 - \frac{1}{2}}  \int_{-h}^{t} \exp\left(\frac{\frac{-1}{2}}{1 - \frac{1}{2}}(t-s)\right) M_X'(s) ds.\] In this case, the domain of \(M_X(t) = (-\infty, \infty)\), so we let \(-h = -\infty\), and \(M_X'(s) = p\cdot \exp(s)\), thus we obtain:
        \[\leftindex_{CF}{M}_X^{(\frac{1}{2})} = 2  \int_{-\infty}^{t} \exp\left((s-t)\right) \cdot (p\cdot \exp(s)) ds.\]
        \[= 2p \cdot \exp(-t) \int_{-\infty}^{t}\exp(2s) ds\] 
        \[= p\cdot \exp(-t) \left(\exp(2s) \Big|_{-\infty}^{t}\right) = p\cdot \exp(t)\]
        Now, all that is left to do is set \(t = 0\) and we obtain that \(\leftindex_{CF}{M}_X^{(\frac{1}{2})} = p\).
        \item Computing \(\mathbb{E}[{X^{\frac{1}{2}}}]\) in the traditional fashion, we obtain: 
        \[\mathbb{E}[{X^{\frac{1}{2}}}] = \sum_x x^{\frac{1}{2}} \mathbb{P}(X = x) = 0^{\frac{1}{2}} \cdot \mathbb{P}(X = 0) + 1^{\frac{1}{2}} \cdot \mathbb{P}(X = 1)\]
        \[ = 0 \cdot(1 - p) + 1 \cdot p = p\]
    \end{enumerate}
    
\end{example}
It is amazing and maybe even somewhat surprising that both expressions obtain the same result. Indeed, this result is actually more of a coincidence. It is important to note that this agreement of results is coincidental and specific to the chosen distribution. Namely, all raw higher moments of a Bernoulli random variable are \(p\). If we had taken any other distribution in combination with a moment of fractional order, it becomes highly likely that the MGF returns a different value compared to the traditional method of computing moments. What is more, if we were to take \[\leftindex_{RL}{M}_X^{(\frac{1}{2})}  = \frac{d}{dt} \frac{1}{\sqrt{\pi}}  \int_{-h}^{t} (t - s)^{\frac{-1}{2}} f(s) ds\] we obtain an integral which may diverge based on the choice of \(-h\) . These observations lead to the following theorem.

\begin{theorem}\label{t: MGF_accurate}
     Consider the three MGF's as defined in definition \ref{d: MGF}. Assume \(\leftindex_{RL}{M}_X^{(\alpha)}\) and \(\leftindex_{GL}{M}_X^{(\alpha)}\) are well defined on some open interval \((-h, h)\), then the moment generating function expressions \(\leftindex_{RL}{M}_X^{(\alpha)}\) and \(\leftindex_{GL}{M}_X^{(\alpha)}\) accurately obtain moments of order \(\alpha \in \mathbb{R}\)
    
\end{theorem}
The proof can be found in Appendix \ref{s:app_B}.
\newline
Unfortunately, this result does not hold for \(\leftindex_{CF}{M}_X^{(\alpha)}\), which leads to the following theorem.

\begin{theorem}\label{t: MGF_inaccurate}
    Consider the three MGF's as defined in definition \ref{d: MGF}. Assume \(\leftindex_{CF}{M}_X^{(\alpha)}\) is well defined on some open interval \((-h, h)\), then the moment generating function expression \(\leftindex_{CF}{M}_X^{(\alpha)}\) inaccurately approximates moments of order \(\alpha \in \mathbb{R}\) with approximation error given by
    \[
\begin{cases} 
    \displaystyle \int_{-\infty}^{\infty} x^\alpha  f_X(x) dx -  \displaystyle \int_{-\infty}^{\infty}  \frac{x^{n+1} }{(1 - \beta)x + \beta} f_X(x) dx & \text{if } X \text{ is continuous,} \\ 
    \displaystyle \sum_{i} \left(x_i^\alpha -  \frac{x_i^{n+1} }{(1 - \beta)x_i + \beta}\right) f_X(x_i) & \text{if } X \text{ is discrete.} 
\end{cases}
\] with \(\alpha \in \mathbb{R}, \beta = \alpha - n \text{ and } n = \lfloor \alpha \rfloor.\)
    
\end{theorem}
The proof can be found in Appendix \ref{s:app_B}.

\begin{remark}
    In the case when \(\alpha \in \mathbb{N}\), we have that \(n = \alpha\), and thus \( \beta = 0\), therefore, \(\leftindex_{CF}{M}_X^{(\alpha)}\) is accurate for integer orders. This is an expected result, as the MGF for integer moments is accurate and from section \ref{s:calculus} we know that \(D_{CF}^{\alpha + \beta}f(x) = D_{CF}^\alpha(D_{CF}^\beta f(x))\), with \(\alpha \in \mathbb{N}, \beta \in [0, 1).\) In this case, let \(\beta = 0\). So we get \(D_{CF}^{\alpha + 0}f(x) = D_{CF}^{\alpha}f(x)\) which is just a regular derivative of integer order.
\end{remark}
